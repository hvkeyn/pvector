
# UPVector Server

UPVector Server — это универсальный веб-краулер и прокси-менеджер, реализованный с использованием FastAPI и Playwright. Сервер поддерживает GET и POST-запросы, обработку страниц с использованием прокси, управление прокси и возврат заголовков и cookies.

## Особенности

- **Краулинг веб-страниц**:
  - GET и POST-запросы.
  - Использование пользовательских заголовков и cookies.
  - Поддержка внутренних и внешних прокси.

- **Прокси-менеджер**:
  - Добавление, удаление, список прокси.
  - Проверка доступности прокси.

- **Возврат метаинформации**:
  - Cookies, заголовки, время отклика.

---

## Установка

### 1. Клонирование репозитория

```bash
git clone https://github.com/hvkeyn/upvector.git
cd upvector
```

### 2. Установка зависимостей

Создайте виртуальное окружение и установите зависимости:

```bash
python -m venv .venv
source .venv/bin/activate    # Linux/macOS
.venv\Scripts\activate       # Windows

pip install -r requirements.txt
playwright install
```

---

## Запуск сервера

Для запуска сервера используйте:

```bash
python vector.py
```

Сервер будет запущен на порту `8000` (по умолчанию).

---

## Тестирование

Для проверки работы сервера запустите тестовый клиент:

```bash
python test.py
```

---

## API-эндпоинты

### 1. Системные маршруты

| Маршрут             | Метод | Описание                                   |
|---------------------|-------|-------------------------------------------|
| `/test_connection`  | GET   | Проверка соединения с сервером.           |
| `/routes`           | GET   | Список всех доступных маршрутов.          |

---

### 2. Прокси-менеджер

| Маршрут             | Метод | Описание                                   |
|---------------------|-------|-------------------------------------------|
| `/proxy/add`        | POST  | Добавить прокси.                          |
| `/proxy/remove`     | DELETE| Удалить прокси.                           |
| `/proxy/list`       | GET   | Получить список всех прокси.              |
| `/proxy/check`      | GET   | Проверить статус одного прокси.           |
| `/proxy/check/all`  | GET   | Проверить все прокси.                     |

Пример запроса для добавления прокси:
```json
{
  "proxy": "127.0.0.1:8080"
}
```

---

### 3. Краулинг

| Маршрут             | Метод | Описание                                   |
|---------------------|-------|-------------------------------------------|
| `/crawl`            | POST  | Одиночный GET-запрос.                     |
| `/post_crawl`       | POST  | POST-запрос с параметрами и cookies.      |
| `/crawl/multiple`   | POST  | Множественные запросы.                    |

Пример тела запроса для `/post_crawl`:
```json
{
  "url": "https://httpbin.org/post",
  "post_data": {"key": "value"},
  "headers": {"Authorization": "Bearer test-token"},
  "cookies": {"session_id": "12345"}
}
```

---

## Зависимости

Проект использует следующие библиотеки:

- `fastapi` — для реализации API.
- `playwright` — для работы с браузером.
- `aiohttp` — для асинхронных HTTP-запросов.
- `uvicorn` — сервер для запуска FastAPI.

Установите зависимости через `requirements.txt`.

---

## Пример использования

Тестовые запросы можно найти в файле `test.py`. Для выполнения тестов выполните:

```bash
python test.py
```

---

## Лицензия

Этот проект распространяется под лицензией Apache-2.0. Подробнее смотрите в файле `LICENSE`.
